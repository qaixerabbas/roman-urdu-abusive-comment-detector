{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB955eY0zYXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('final.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxeNKsk_02dv",
        "colab_type": "code",
        "outputId": "4cfaae80-bbf7-4a05-9447-f3328589da70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEJDUNep043y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getVectors(corpus,vectors,size):\n",
        "    wordset = set(vectors.wv.index2word) #Checks if the word is in the Word2vec corpus \n",
        "    vec = []\n",
        "    counter = 0\n",
        "    for words in corpus:    \n",
        "        featureVec = np.zeros(size,dtype=\"object\")\n",
        "        for word in words:\n",
        "            if word in wordset:\n",
        "                featureVec = np.add(featureVec,vectors[word])\n",
        "        vec.append(featureVec.T)\n",
        "        counter = counter + 1\n",
        "        #print(counter)\n",
        "    return vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mYb8pxP09vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for words in data.comment:\n",
        "    words = words.split()\n",
        "    corpus.append(words)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mp6gs-1BZ3",
        "colab_type": "code",
        "outputId": "9f7f1aee-8195-49ae-b2dd-d36e03d4bd9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "Y = to_categorical(data.rating)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA6sAWWz1KFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, y_test = train_test_split(corpus,Y, test_size = 0.20, random_state = 123)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjwVyj8O1Mxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 300\n",
        "min_counts = 10\n",
        "context = 5\n",
        "n_workers = 15\n",
        "down_sample = 1e-2\n",
        "vectors = wv.Word2Vec(X_train,\n",
        "                     size = vocab_size,\n",
        "                     workers =n_workers,\n",
        "                     window = context,\n",
        "                     min_count = min_counts,\n",
        "                     sample = down_sample)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSFeR3MR1PXJ",
        "colab_type": "code",
        "outputId": "0f1d55a7-fbd4-47e2-da4a-b86c02b4309d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = getVectors(X_train,vectors,vocab_size)\n",
        "X_test = getVectors(X_test,vectors,vocab_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GYNZrCO1Vj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrbfAC8R2Pxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import layers\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akHrjSoN2Tb0",
        "colab_type": "code",
        "outputId": "1fd35d3c-2f87-4ec4-a128-49492f9e68eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu', input_dim = vocab_size,kernel_regularizer= regularizers.l2(0.0001)))\n",
        "classifier.add(layers.Dropout(0.2))\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu'))\n",
        "#classifier.add(layers.Dropout(0.25))\n",
        "# Adding the third hidden layer\n",
        "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu',kernel_regularizer= regularizers.l2(0.0001)))\n",
        "#classifier.add(layers.Dropout(0.25))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(output_dim = 2, init = 'uniform', activation = 'softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=300, kernel_regularizer=<keras.reg..., units=1024, kernel_initializer=\"uniform\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024, kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=1024, kernel_initializer=\"uniform\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2, kernel_initializer=\"uniform\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3p2hwPu2aPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoWSVpnJ2cq5",
        "colab_type": "code",
        "outputId": "81c0aced-bac5-4ea3-efd6-587b2d72308f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train, Y_train, batch_size = 50, epochs = 100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "130139/130139 [==============================] - 26s 203us/step - loss: 0.4174 - acc: 0.8459\n",
            "Epoch 2/100\n",
            "130139/130139 [==============================] - 25s 193us/step - loss: 0.3515 - acc: 0.8622\n",
            "Epoch 3/100\n",
            "130139/130139 [==============================] - 25s 193us/step - loss: 0.3408 - acc: 0.8656\n",
            "Epoch 4/100\n",
            "130139/130139 [==============================] - 25s 191us/step - loss: 0.3328 - acc: 0.8678\n",
            "Epoch 5/100\n",
            "130139/130139 [==============================] - 25s 190us/step - loss: 0.3318 - acc: 0.8684\n",
            "Epoch 6/100\n",
            "130139/130139 [==============================] - 25s 190us/step - loss: 0.3255 - acc: 0.8704\n",
            "Epoch 7/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3230 - acc: 0.8712\n",
            "Epoch 8/100\n",
            "130139/130139 [==============================] - 25s 190us/step - loss: 0.3214 - acc: 0.8724\n",
            "Epoch 9/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3192 - acc: 0.8722\n",
            "Epoch 10/100\n",
            "130139/130139 [==============================] - 25s 190us/step - loss: 0.3180 - acc: 0.8737\n",
            "Epoch 11/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3168 - acc: 0.8735\n",
            "Epoch 12/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3142 - acc: 0.8740\n",
            "Epoch 13/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3235 - acc: 0.8719\n",
            "Epoch 14/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3163 - acc: 0.8745\n",
            "Epoch 15/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3114 - acc: 0.8768\n",
            "Epoch 16/100\n",
            "130139/130139 [==============================] - 25s 189us/step - loss: 0.3092 - acc: 0.8763\n",
            "Epoch 17/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3112 - acc: 0.8765\n",
            "Epoch 18/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3094 - acc: 0.8772\n",
            "Epoch 19/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3104 - acc: 0.8767\n",
            "Epoch 20/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3073 - acc: 0.8773\n",
            "Epoch 21/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3063 - acc: 0.8768\n",
            "Epoch 22/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3086 - acc: 0.8770\n",
            "Epoch 23/100\n",
            "130139/130139 [==============================] - 25s 188us/step - loss: 0.3078 - acc: 0.8774\n",
            "Epoch 24/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3051 - acc: 0.8786\n",
            "Epoch 25/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3046 - acc: 0.8786\n",
            "Epoch 26/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3051 - acc: 0.8784\n",
            "Epoch 27/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3054 - acc: 0.8786\n",
            "Epoch 28/100\n",
            "130139/130139 [==============================] - 24s 188us/step - loss: 0.3040 - acc: 0.8791\n",
            "Epoch 29/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3053 - acc: 0.8777\n",
            "Epoch 30/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3033 - acc: 0.8791\n",
            "Epoch 31/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3045 - acc: 0.8787\n",
            "Epoch 32/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3031 - acc: 0.8791\n",
            "Epoch 33/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3044 - acc: 0.8791\n",
            "Epoch 34/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3030 - acc: 0.8788\n",
            "Epoch 35/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3031 - acc: 0.8791\n",
            "Epoch 36/100\n",
            "130139/130139 [==============================] - 24s 188us/step - loss: 0.3022 - acc: 0.8793\n",
            "Epoch 37/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3027 - acc: 0.8802\n",
            "Epoch 38/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3023 - acc: 0.8789\n",
            "Epoch 39/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3028 - acc: 0.8793\n",
            "Epoch 40/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3016 - acc: 0.8798\n",
            "Epoch 41/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3024 - acc: 0.8791\n",
            "Epoch 42/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.3028 - acc: 0.8783\n",
            "Epoch 43/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.3019 - acc: 0.8789\n",
            "Epoch 44/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.3006 - acc: 0.8800\n",
            "Epoch 45/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3015 - acc: 0.8792\n",
            "Epoch 46/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3005 - acc: 0.8798\n",
            "Epoch 47/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.2999 - acc: 0.8800\n",
            "Epoch 48/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.2996 - acc: 0.8803\n",
            "Epoch 49/100\n",
            "130139/130139 [==============================] - 24s 187us/step - loss: 0.3008 - acc: 0.8798\n",
            "Epoch 50/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.3015 - acc: 0.8801\n",
            "Epoch 51/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.2997 - acc: 0.8801\n",
            "Epoch 52/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.2995 - acc: 0.8796\n",
            "Epoch 53/100\n",
            "130139/130139 [==============================] - 24s 186us/step - loss: 0.2993 - acc: 0.8806\n",
            "Epoch 54/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.2998 - acc: 0.8798\n",
            "Epoch 55/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.3015 - acc: 0.8798\n",
            "Epoch 56/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.3028 - acc: 0.8798\n",
            "Epoch 57/100\n",
            "130139/130139 [==============================] - 24s 184us/step - loss: 0.2990 - acc: 0.8816\n",
            "Epoch 58/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2995 - acc: 0.8811\n",
            "Epoch 59/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2986 - acc: 0.8805\n",
            "Epoch 60/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2991 - acc: 0.8801\n",
            "Epoch 61/100\n",
            "130139/130139 [==============================] - 24s 184us/step - loss: 0.2984 - acc: 0.8810\n",
            "Epoch 62/100\n",
            "130139/130139 [==============================] - 24s 184us/step - loss: 0.2978 - acc: 0.8810\n",
            "Epoch 63/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2977 - acc: 0.8819\n",
            "Epoch 64/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.3005 - acc: 0.8806\n",
            "Epoch 65/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2983 - acc: 0.8809\n",
            "Epoch 66/100\n",
            "130139/130139 [==============================] - 24s 184us/step - loss: 0.2965 - acc: 0.8817\n",
            "Epoch 67/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.3017 - acc: 0.8801\n",
            "Epoch 68/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2986 - acc: 0.8810\n",
            "Epoch 69/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2979 - acc: 0.8805\n",
            "Epoch 70/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2989 - acc: 0.8812\n",
            "Epoch 71/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2974 - acc: 0.8817\n",
            "Epoch 72/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2962 - acc: 0.8819\n",
            "Epoch 73/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2973 - acc: 0.8814\n",
            "Epoch 74/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2998 - acc: 0.8803\n",
            "Epoch 75/100\n",
            "130139/130139 [==============================] - 24s 184us/step - loss: 0.2977 - acc: 0.8811\n",
            "Epoch 76/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2966 - acc: 0.8823\n",
            "Epoch 77/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2975 - acc: 0.8817\n",
            "Epoch 78/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2976 - acc: 0.8817\n",
            "Epoch 79/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2967 - acc: 0.8818\n",
            "Epoch 80/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2962 - acc: 0.8812\n",
            "Epoch 81/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2975 - acc: 0.8814\n",
            "Epoch 82/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2979 - acc: 0.8818\n",
            "Epoch 83/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2970 - acc: 0.8816\n",
            "Epoch 84/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2970 - acc: 0.8811\n",
            "Epoch 85/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2963 - acc: 0.8819\n",
            "Epoch 86/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2974 - acc: 0.8814\n",
            "Epoch 87/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2975 - acc: 0.8819\n",
            "Epoch 88/100\n",
            "130139/130139 [==============================] - 24s 185us/step - loss: 0.2965 - acc: 0.8822\n",
            "Epoch 89/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2959 - acc: 0.8817\n",
            "Epoch 90/100\n",
            "130139/130139 [==============================] - 24s 181us/step - loss: 0.2964 - acc: 0.8816\n",
            "Epoch 91/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2977 - acc: 0.8807\n",
            "Epoch 92/100\n",
            "130139/130139 [==============================] - 24s 183us/step - loss: 0.2972 - acc: 0.8804\n",
            "Epoch 93/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2956 - acc: 0.8821\n",
            "Epoch 94/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2957 - acc: 0.8819\n",
            "Epoch 95/100\n",
            "130139/130139 [==============================] - 24s 181us/step - loss: 0.2964 - acc: 0.8814\n",
            "Epoch 96/100\n",
            "130139/130139 [==============================] - 24s 181us/step - loss: 0.2965 - acc: 0.8828\n",
            "Epoch 97/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2952 - acc: 0.8819\n",
            "Epoch 98/100\n",
            "130139/130139 [==============================] - 24s 182us/step - loss: 0.2951 - acc: 0.8818\n",
            "Epoch 99/100\n",
            "130139/130139 [==============================] - 24s 181us/step - loss: 0.2954 - acc: 0.8819\n",
            "Epoch 100/100\n",
            "130139/130139 [==============================] - 24s 181us/step - loss: 0.2970 - acc: 0.8819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1273fd10f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWenziO12gTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred,axis = 1)\n",
        "#y_test = np.argmax(y_test,axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb8D7E1d8jrI",
        "colab_type": "code",
        "outputId": "2619d7f5-43a3-4612-8e5d-68885dcbd834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8803442446595974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fpBqN9tzE5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC4xq_Cy8l9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}