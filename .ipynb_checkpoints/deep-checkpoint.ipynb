{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZB955eY0zYXq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zxeNKsk_02dv",
    "outputId": "68d1a5e8-19e7-4b92-a309-2bef1da3b4bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEJDUNep043y"
   },
   "outputs": [],
   "source": [
    "def getVectors(corpus,vectors,size):\n",
    "    wordset = set(vectors.wv.index2word) #Checks if the word is in the Word2vec corpus \n",
    "    vec = []\n",
    "    counter = 0\n",
    "    for words in corpus:    \n",
    "        featureVec = np.zeros(size,dtype=\"object\")\n",
    "        for word in words:\n",
    "            if word in wordset:\n",
    "                featureVec = np.add(featureVec,vectors[word])\n",
    "        vec.append(featureVec.T)\n",
    "        counter = counter + 1\n",
    "        #print(counter)\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mYb8pxP09vK"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for words in data.comment:\n",
    "    words = words.split()\n",
    "    corpus.append(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d2mp6gs-1BZ3",
    "outputId": "fc1e3397-0191-48fc-957a-46bbdb188537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(data.rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QA6sAWWz1KFX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, y_test = train_test_split(corpus,Y, test_size = 0.20, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjwVyj8O1Mxt"
   },
   "outputs": [],
   "source": [
    "import gensim.models.word2vec as wv\n",
    "vocab_size = 300\n",
    "min_counts = 10\n",
    "context = 5\n",
    "n_workers = 15\n",
    "down_sample = 1e-2\n",
    "vectors = wv.Word2Vec(X_train,\n",
    "                     size = vocab_size,\n",
    "                     workers =n_workers,\n",
    "                     window = context,\n",
    "                     min_count = min_counts,\n",
    "                     sample = down_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "qSFeR3MR1PXJ",
    "outputId": "63791ccc-cf0a-4985-a275-448fac4dd9b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = getVectors(X_train,vectors,vocab_size)\n",
    "X_test = getVectors(X_test,vectors,vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GYNZrCO1Vj1"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrbfAC8R2Pxa"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "akHrjSoN2Tb0",
    "outputId": "04a6da50-8735-4233-ba0d-33612f14bcc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=300, kernel_regularizer=<keras.reg..., units=1024, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=1024, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu', input_dim = vocab_size,kernel_regularizer= regularizers.l2(0.0001)))\n",
    "classifier.add(layers.Dropout(0.2))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu'))\n",
    "#classifier.add(layers.Dropout(0.25))\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim =1024, init = 'uniform', activation = 'relu',kernel_regularizer= regularizers.l2(0.0001)))\n",
    "#classifier.add(layers.Dropout(0.25))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 2, init = 'uniform', activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3p2hwPu2aPP"
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2145
    },
    "colab_type": "code",
    "id": "JoWSVpnJ2cq5",
    "outputId": "56a9653c-4565-4464-ffd1-65329b54ac3d"
   },
   "outputs": [],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, Y_train, batch_size = 50, epochs = 60,verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWenziO12gTW"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "y_test = np.argmax(y_test,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eb8D7E1d8jrI",
    "outputId": "be2b6add-60be-4a04-eb74-142fa7755c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8829568157368988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fpBqN9tzE5c"
   },
   "outputs": [],
   "source": [
    "classifier.save(\"deep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lC4xq_Cy8l9X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
